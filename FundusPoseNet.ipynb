{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FundusPoseNet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kDha33MuaUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations\n",
        "# This lib is required only for training, restart runtime if downloaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT9F-PEa_trA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### You can skip the training procedure and move directly for testing using pre-trained weights further down below #####################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j1RHEXk207X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################################### Image pre-processing and augmentation pipeline setup ####################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggx4cVjou1Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enable GPU option in notebook settings\n",
        "\n",
        "# deep learning and machine learning frameworks\n",
        "%tensorflow_version 2.x\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# image processing lib\n",
        "import numpy as np\n",
        "from numpy.random import permutation\n",
        "import albumentations as albu\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math \n",
        "import random\n",
        "import math\n",
        "\n",
        "# file management\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjREFmcHu25p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mounting google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEAaR_IHu7tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate npy files for training dataset\n",
        "# On execution of this cell you will transform the IDRiD training images to 128x128x3 dimensions, and the co-cordinates are also re-scaled to 128x128 image space\n",
        "\n",
        "# prepare train dataset\n",
        "fovpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/2. Fovea Center Location/IDRiD_Fovea_Center_Training Set_Markups.csv'\n",
        "odpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/1. Optic Disc Center Location/a. IDRiD_OD_Center_Training Set_Markups.csv'\n",
        "imglist = os.listdir(\"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/a. Training Set\")\n",
        "imgpath = \"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/a. Training Set/{}\"\n",
        "\n",
        "fov = pd.read_csv(fovpath, encoding='utf-8')\n",
        "od = pd.read_csv(odpath, encoding='utf-8')\n",
        "\n",
        "print(len(fov), len(od), len(imglist))\n",
        "\n",
        "x = []\n",
        "y = np.zeros((len(imglist), 4))\n",
        "S = 128 # image resolution of generated npy files\n",
        "for p in enumerate(imglist):\n",
        "  i = p[0]\n",
        "  p = p[1]\n",
        "  img = cv2.imread(imgpath.format(p))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  H, W = img.shape[0], img.shape[1] \n",
        "  o = od.loc[od['Image No'] == p.split('.')[0]].iloc[0]\n",
        "  f = fov.loc[fov['Image No'] == p.split('.')[0]].iloc[0]\n",
        "  # scale the dimension     \n",
        "  y[i] = [o['X- Coordinate']/W*S, o['Y - Coordinate']/H*S,\n",
        "          f['X- Coordinate']/W*S, f['Y - Coordinate']/H*S]  \n",
        "  x.append(cv2.resize(img, (S, S), interpolation=cv2.INTER_AREA))\n",
        "\n",
        "x = np.array(x)\n",
        "print(x.shape, y.shape)\n",
        "print(x.max(), y.max())\n",
        "print(x.min(), y.min())\n",
        "\n",
        "# save train data \n",
        "np.save('drive/My Drive/FundusPoseNet/npy/x_train.npy', x)\n",
        "np.save('drive/My Drive/FundusPoseNet/npy/y_train.npy', y)\n",
        "\n",
        "################################################################################################################################\n",
        "\n",
        "# prepare val dataset (we used IDRiD test set as val set during training)\n",
        "fovpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/2. Fovea Center Location/IDRiD_Fovea_Center_Testing Set_Markups.csv'\n",
        "odpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/1. Optic Disc Center Location/b. IDRiD_OD_Center_Testing Set_Markups.csv'\n",
        "imglist = os.listdir(\"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set\")\n",
        "imgpath = \"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set/{}\"\n",
        "\n",
        "fov = pd.read_csv(fovpath, encoding='utf-8')\n",
        "od = pd.read_csv(odpath, encoding='utf-8')\n",
        "\n",
        "print(len(fov), len(od), len(imglist))\n",
        "\n",
        "x = []\n",
        "y = np.zeros((len(imglist), 4))\n",
        "S = 128 # image resolution of generated npy files\n",
        "for p in enumerate(imglist):\n",
        "  i = p[0]\n",
        "  p = p[1]\n",
        "  img = cv2.imread(imgpath.format(p))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  H, W = img.shape[0], img.shape[1] \n",
        "  o = od.loc[od['Image No'] == p.split('.')[0]].iloc[0]\n",
        "  f = fov.loc[fov['Image No'] == p.split('.')[0]].iloc[0]\n",
        "  # scale the dimension     \n",
        "  y[i] = [o['X- Coordinate']/W*S, o['Y - Coordinate']/H*S,\n",
        "          f['X- Coordinate']/W*S, f['Y - Coordinate']/H*S]  \n",
        "  x.append(cv2.resize(img, (S, S), interpolation=cv2.INTER_AREA))\n",
        "\n",
        "x = np.array(x)\n",
        "print(x.shape, y.shape)\n",
        "print(x.max(), y.max())\n",
        "print(x.min(), y.min())\n",
        "\n",
        "# save val data \n",
        "np.save('drive/My Drive/FundusPoseNet/npy/x_val.npy', x)\n",
        "np.save('drive/My Drive/FundusPoseNet/npy/y_val.npy', y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWbQDbvEwtN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "x_train = np.load(\"drive/My Drive/FundusPoseNet/npy/x_train.npy\")/255.0\n",
        "y_train = np.load(\"drive/My Drive/FundusPoseNet/npy/y_train.npy\")\n",
        "x_val = np.load(\"drive/My Drive/FundusPoseNet/npy/x_val.npy\")/255.0\n",
        "y_val = np.load(\"drive/My Drive/FundusPoseNet/npy/y_val.npy\")\n",
        "\n",
        "# shuffle the images\n",
        "perm = np.random.permutation(len(x_train))\n",
        "x_train = x_train[perm]\n",
        "y_train = y_train[perm]\n",
        "\n",
        "# log important data about pre-processed data\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_train.max(), y_train.max())\n",
        "print(x_train.min(), y_train.min())\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_val.max(), y_val.max())\n",
        "print(x_val.min(), y_val.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNQf2y8vsVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image augmentation pipeline\n",
        "# A batch of image is sampled from x_train and heatmaps are generated during the runtime by the augmentor() generator\n",
        "\n",
        "def gaussian_heatmap(x0, y0, isFov, width=128, height=128):\n",
        "  \"\"\" Make a square gaussian kernel centered at (x0, y0) with sigma as SD.\n",
        "  \"\"\"\n",
        "  if isFov == 1:\n",
        "    # for fovea sigma is selected as 10.0\n",
        "    sigma = 10.0\n",
        "  else:\n",
        "    # for optic disc sigma is selected as 8.0\n",
        "    sigma = 8.0    \n",
        "  x = np.arange(0, width, 1, float)\n",
        "  y = np.arange(0, height, 1, float)[:, np.newaxis]\n",
        "  # generate and return the heatmap\n",
        "  return np.exp(-((x-x0)**2 + (y-y0)**2) / (2*sigma**2))\n",
        "\n",
        "def apply_transforms(transformations, image, points):\n",
        "  return albu.Compose(transformations, p=0.5, \n",
        "                      keypoint_params=albu.KeypointParams(format='xy'))(image=image, keypoints=points)\n",
        "\n",
        "def augmentor(batch):\n",
        "  while True:  \n",
        "    batch_x, batch_y = next(batch) # obtain a batch\n",
        "    IMGS = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], batch_x.shape[3])) # placeholder for transformed image\n",
        "    MASKS = np.zeros((batch_x.shape[0], batch_x.shape[1], batch_x.shape[2], batch_y.shape[1]//2)) # placeholder for masks   \n",
        "    for data in enumerate(zip(batch_x, batch_y)):\n",
        "      img = data[1][0] # image\n",
        "      kvec = data[1][1] # keypoints\n",
        "      kps = np.array([(kvec[k], kvec[k+1]) for k in range(0, batch_y.shape[1]-1, 2)])\n",
        "      res = apply_transforms([albu.VerticalFlip(p=0.5),\n",
        "                              albu.HorizontalFlip(p=0.5),\n",
        "                              albu.ShiftScaleRotate(p=0.5, shift_limit=0.0, rotate_limit=0, scale_limit=0.4, border_mode=cv2.BORDER_CONSTANT)],\n",
        "                              img, kps)\n",
        "      \n",
        "      IMGS[data[0]] = res['image']\n",
        "      for k in range(0, batch_y.shape[1]//2):\n",
        "        try:\n",
        "          MASKS[data[0], :, :, k] = gaussian_heatmap(res['keypoints'][k][0], res['keypoints'][k][1], k)\n",
        "        except:\n",
        "          IMGS[data[0]] = IMGS[0]\n",
        "          MASKS[data[0]] = MASKS[0]\n",
        "          print(\"Error occured in augmentation\")  \n",
        "    del batch_x, batch_y\n",
        "    # generates a batch of augmented images and labels during runtime of training \n",
        "    yield (IMGS, MASKS)\n",
        "\n",
        "# split data for training and validation in 9:1 ratio \n",
        "SEED=None\n",
        "BATCH_SIZE=12\n",
        "KPS = 2\n",
        "C = 3\n",
        "IMG_SIZE=128\n",
        "\n",
        "data_gen_args = dict(brightness_range=[0.5, 1.5],\n",
        "                     rescale=1./255)\n",
        "gen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n",
        "# prepare the train and val generators\n",
        "train_gen = augmentor(gen.flow(x_train, y_train, batch_size=BATCH_SIZE, seed=SEED)) \n",
        "val_gen = augmentor(gen.flow(x_val, y_val, batch_size=BATCH_SIZE, seed=SEED)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnjpkhgUxfJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample batch of data from the augmentation pipeline to verify if images are augmented as required\n",
        "for imgs, masks in train_gen:\n",
        "  print(masks.max(), imgs.max())\n",
        "  print(masks.shape, imgs.shape)\n",
        "  for img, mask in zip(imgs, masks):\n",
        "    for k in range(KPS):\n",
        "      plt.axis('off')\n",
        "      plt.imshow(mask[:, :, k], cmap='gray')\n",
        "      plt.show()\n",
        "    m = np.sum(mask, axis=-1, keepdims=True)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img) \n",
        "    plt.show()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(m*img)\n",
        "    plt.show()    \n",
        "    break\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujYdszC2-gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################################### Model Architecture and training ####################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiZK5XOyxosL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder and decoder blocks\n",
        "def Encoder(x, k, ks, dr, a=0.1):\n",
        "  x = tf.keras.layers.Conv2D(2 * k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)\n",
        "  x = tf.keras.layers.Conv2D(k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)\n",
        "  x = tf.keras.layers.Conv2D(2 * k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x) \n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)  \n",
        "  pool = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
        "  return x, pool\n",
        "\n",
        "def Decoder(x, skip, k, ks, dr, a=0.1):\n",
        "  x = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(k, kernel_size=(2, 2), strides=(2, 2), padding='same')(x), skip])\n",
        "  x = tf.keras.layers.Conv2D(2 * k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)\n",
        "  x = tf.keras.layers.Conv2D(k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)\n",
        "  x = tf.keras.layers.Conv2D(2 * k, kernel_size=(ks, ks), strides=(1, 1), padding='same', dilation_rate=(dr, dr))(x) \n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=a)(x)  \n",
        "  return x\n",
        "\n",
        "def BuildModel(k, IMG_SIZE=128, KPS=2, C=3):\n",
        "  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, C))\n",
        "  conv1, pool1 = Encoder(inputs, k, 7, 1)\n",
        "  k = k * 2\n",
        "  conv2, pool2 = Encoder(pool1, k, 5, 1)\n",
        "  k = k * 2\n",
        "  conv3, pool3 = Encoder(pool2, k, 3, 1)\n",
        "  k = k * 2\n",
        "  conv4, pool4 = Encoder(pool3, k, 3, 2)\n",
        "  k = k * 2\n",
        "  conv5, _ = Encoder(pool4, k, 3, 2)\n",
        "  deconv1 = Decoder(conv5, conv4, k, 3, 2)\n",
        "  k = k // 2\n",
        "  deconv2 = Decoder(deconv1, conv3, k, 3, 1)\n",
        "  k = k // 2\n",
        "  deconv3 = Decoder(deconv2, conv2, k, 5, 1)\n",
        "  k = k // 2\n",
        "  deconv4 = Decoder(deconv3, conv1, k, 7, 1)\n",
        "  outputs = tf.keras.layers.Conv2D(KPS, kernel_size=(1, 1))(deconv4)\n",
        "  outputs = tf.keras.layers.BatchNormalization()(outputs)\n",
        "  outputs = tf.keras.layers.Activation('sigmoid')(outputs)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "  return model   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cKD_s5WxrIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "fp = BuildModel(16)\n",
        "fp.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
        "           loss='binary_crossentropy')\n",
        "\n",
        "# uncomment the following line, to continue training from last checkpoint\n",
        "fp.summary()\n",
        "\n",
        "# checkpoint to save the model architecture, optimizer state and model weights and biases\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"drive/My Drive/FundusPoseNet/models/FPN.model\",\n",
        "                                                monitor='val_loss', # monitor the val loss\n",
        "                                                verbose=1,\n",
        "                                                save_best_only=True,\n",
        "                                                save_weights_only=False,\n",
        "                                                mode='min', # save model if val loss is less\n",
        "                                                period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJizSCDWx87K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "history = fp.fit_generator(train_gen,\n",
        "                 steps_per_epoch=x_train.shape[0] // BATCH_SIZE,\n",
        "                 epochs=400,\n",
        "                 verbose=1,\n",
        "                 callbacks=[checkpoint],\n",
        "                 validation_data=val_gen,\n",
        "                 validation_steps=x_val.shape[0] // BATCH_SIZE,\n",
        "                 shuffle=True)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSYSw6f3yM1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot curves\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.ylabel('train_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtRaxzsF3HYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################### Testing and intermediate layer analysis #############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ecdSqmWydzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment line 2 to load the pre-trained model\n",
        "# model = tf.keras.models.load_model(\"drive/My Drive/FundusPoseNet/models/FundusPoseNet128\") # ignore any warnings\n",
        "# Uncomment line 4 to load the model you just trained \n",
        "model = tf.keras.models.load_model(\"drive/My Drive/FundusPoseNet/models/FPN.model\") # re-run cell 2 (mount the drive again if it thorws any file not found error)\n",
        "IMG_SIZE = 128 # input image size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QocS3m6v1_B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################ Test the model on IDRiD test dataset and view the results ##################################################### "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsODNbgOzlE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def EDprediction(paths, imgpath):\n",
        "  count = 0\n",
        "  predictedPos = []\n",
        "  imName = []\n",
        "  print(len(paths))\n",
        "  for p in paths:\n",
        "    try:\n",
        "      # pre-process raw image\n",
        "      img = cv2.imread(imgpath.format(p))\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      # find the dimension re-scaling factor\n",
        "      rH, rW = (1. * img.shape[0])/(1. * IMG_SIZE), (1. * img.shape[1])/(1. * IMG_SIZE)\n",
        "      # resize the image \n",
        "      img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)/255.0\n",
        "      # feed the input image\n",
        "      output = model.predict([img.reshape(1, IMG_SIZE, IMG_SIZE, 3)])   \n",
        "      points = []\n",
        "      for i in range(2): \n",
        "        # apply gaussian blur using 25x25 kerenl\n",
        "        blur = cv2.GaussianBlur(np.uint8(output[0, :, :, i]*255.0), (25, 25), 0)\n",
        "        # apply otsu's thresholding\n",
        "        _,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "        # detect the countours    \n",
        "        cnts, _ = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        max_area_index = [cv2.contourArea(cnt) for cnt in cnts]\n",
        "        index = max_area_index.index(max(max_area_index))\n",
        "        # apply moments on contour with max area\n",
        "        M = cv2.moments(cnts[index])\n",
        "        # find the co-ordinates from moments \n",
        "        cx = M['m10']/M['m00']\n",
        "        cy = M['m01']/M['m00']\n",
        "        points.append(cx*rW)\n",
        "        points.append(cy*rH) \n",
        "      predictedPos.append(points)\n",
        "      imName.append(p.split(\".\")[0])\n",
        "      count = count + 1\n",
        "    except:\n",
        "      print(p)  \n",
        "  print(count)\n",
        "  predictedPos = np.array(predictedPos)\n",
        "  return predictedPos, imName"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zn7E2hQzwhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load test data\n",
        "paths = os.listdir(\"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set\")\n",
        "fovpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/2. Fovea Center Location/IDRiD_Fovea_Center_Testing Set_Markups.csv'\n",
        "odpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/2. Groundtruths/1. Optic Disc Center Location/b. IDRiD_OD_Center_Testing Set_Markups.csv'\n",
        "imgpath = \"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set/{}\"\n",
        "\n",
        "fov = pd.read_csv(fovpath, encoding='utf-8')\n",
        "od = pd.read_csv(odpath, encoding='utf-8')\n",
        "\n",
        "res, imName = EDprediction(paths[:5], imgpath)\n",
        "print(res.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6u-bvj60L2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get euclidean distance\n",
        "edfov = 0.0\n",
        "edod = 0.0\n",
        "count = 0 \n",
        "\n",
        "# blue dot ground truth, red dot is predicted co-ordinate\n",
        "for name in imName:\n",
        "  img = cv2.imread(\"drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set/{}.jpg\".format(name))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  x = fov.loc[fov['Image No'] == name].iloc[0]\n",
        "  pos = imName.index(name)  \n",
        "  px, py = x['X- Coordinate'], x['Y - Coordinate'] \n",
        "  qx, qy = res[pos][2], res[pos][3]\n",
        "  cv2.circle(img, (int(px), int(py)), 20, (255,0,0), -1)\n",
        "  cv2.circle(img, (int(qx), int(qy)), 20, (0,0,255), -1)  \n",
        "  edfov = edfov + math.sqrt(math.pow((px-qx), 2)+math.pow((py-qy), 2))\n",
        "  print(\"edfov: {}\".format(math.sqrt(math.pow((px-qx), 2)+math.pow((py-qy), 2))))\n",
        "\n",
        "  x = od.loc[od['Image No'] == name].iloc[0]\n",
        "  pos = imName.index(name)  \n",
        "  px, py = x['X- Coordinate'], x['Y - Coordinate'] \n",
        "  qx, qy = res[pos][0], res[pos][1]\n",
        "  cv2.circle(img, (int(px), int(py)), 20, (255,0,0), -1)\n",
        "  cv2.circle(img, (int(qx), int(qy)), 20, (0,0,255), -1)\n",
        "  edod = edod + math.sqrt(math.pow((px-qx), 2)+math.pow((py-qy), 2))  \n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  print(\"edod: {}\".format(math.sqrt(math.pow((px-qx), 2)+math.pow((py-qy), 2))))\n",
        "  count = count + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5dgDQM8z9lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display the final score\n",
        "print(edfov, edod, count)  \n",
        "print(edfov/count, edod/count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uFMG1ht2hc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################## Test on one image to view intermediate layers ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDNXR5wf2nMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# single image output testing and layer by layer analysis\n",
        "fp.set_weights(model.get_weights()) \n",
        "inter = [tf.keras.Model(inputs=fp.input, outputs=fp.layers[i].output) for i in range(1, len(model.layers))]\n",
        "\n",
        "imgpath = 'drive/My Drive/FundusPoseNet/IDriD/C. Localization/1. Original Images/b. Testing Set/IDRiD_001.jpg.jpg'\n",
        "\n",
        "img = cv2.imread(imgpath)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "rH, rW = (1. * img.shape[0])/(1. * IMG_SIZE), (1. * img.shape[1])/(1. * IMG_SIZE) \n",
        "img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)/255.0\n",
        "output = model.predict([img.reshape(1, IMG_SIZE, IMG_SIZE, 3)])\n",
        "tmp = fp.predict([img.reshape(1, IMG_SIZE, IMG_SIZE, 3)])\n",
        "try:\n",
        "  for i in range(2, len(model.layers)):\n",
        "    print('Layer {}'.format(i))\n",
        "    o = inter[i].predict([img.reshape(1, IMG_SIZE, IMG_SIZE, 3)])\n",
        "    for j in range(0, o.shape[3], 50): # better keep step=50, otherwise it takes forever\n",
        "      print('Channel {}'.format(j))\n",
        "      plt.imshow(o[0, :, :, j], cmap='gray')\n",
        "      plt.show()\n",
        "except:\n",
        "  pass         \n",
        "points = []\n",
        "for i in range(2):\n",
        "  plt.imshow(output[0, :, :, i], cmap='gray')\n",
        "  plt.show() \n",
        "  blur = cv2.GaussianBlur(np.uint8(output[0, :, :, i]*255.0), (25, 25), 0)\n",
        "  _,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)    \n",
        "  cnts, _ = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  max_area_index = [cv2.contourArea(cnt) for cnt in cnts]\n",
        "  index = max_area_index.index(max(max_area_index))\n",
        "  M = cv2.moments(cnts[index])\n",
        "  cx = M['m10']/M['m00']\n",
        "  cy = M['m01']/M['m00']\n",
        "  img = cv2.drawMarker(img, (int(cx), int(cy)), (255,255,0), markerType=cv2.MARKER_CROSS, \n",
        "                  markerSize=5, thickness=1, line_type=cv2.LINE_AA)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY92ThRB1Vp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################# IGNORE THIS #########################################################################\n",
        "\n",
        "# # save intermediate steps for presenatation/illustration on paper \n",
        "# save_name_template = ['drive/My Drive/Output/{}/od_heatmap.jpg',\n",
        "#                       'drive/My Drive/Output/{}/fov_heatmap.jpg',\n",
        "#                       'drive/My Drive/Output/{}/overlay.jpg',\n",
        "#                       'drive/My Drive/Output/{}/dot_plot.jpg',\n",
        "#                       'drive/My Drive/Output/{}/crosshair.jpg',\n",
        "#                       'drive/My Drive/Output/{}/overlay_dot.jpg',\n",
        "#                       'drive/My Drive/Output/{}/overlay_crosshair.jpg']\n",
        "\n",
        "# for i in range(100):\n",
        "#   p = []\n",
        "#   img = cv2.imread('drive/My Drive/Output/{}/{}'.format(i, os.listdir('drive/My Drive/Output/{}'.format(i))[0]))\n",
        "#   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#   img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)/255.0\n",
        "#   imgo = img.copy()\n",
        "#   imgo = cv2.cvtColor(np.uint8(imgo*255), cv2.COLOR_RGB2BGR)\n",
        "#   output = model.predict([img.reshape(1, IMG_SIZE, IMG_SIZE, 3)])   \n",
        "#   points = []\n",
        "#   pp = imgo.copy()\n",
        "#   pc = imgo.copy()\n",
        "#   o = np.sum(output, axis=-1).reshape(128, 128, 1)\n",
        "#   o = o*imgo\n",
        "#   outputp = o.copy()\n",
        "#   outputc = o.copy()\n",
        "#   cv2.imwrite(save_name_template[0].format(i), output[0, :, :, 0]*255)\n",
        "#   cv2.imwrite(save_name_template[1].format(i), output[0, :, :, 1]*255)\n",
        "#   for j in range(2):\n",
        "#     #plt.imshow(output[0, :, :, j], cmap='gray')\n",
        "#     #plt.show() \n",
        "#     blur = cv2.GaussianBlur(np.uint8(output[0, :, :, j]*255.0), (25, 25), 0)\n",
        "#     _,th = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)    \n",
        "#     cnts, _ = cv2.findContours(th, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#     max_area_index = [cv2.contourArea(cnt) for cnt in cnts]\n",
        "#     index = max_area_index.index(max(max_area_index))\n",
        "#     M = cv2.moments(cnts[index])\n",
        "#     cx = M['m10']/M['m00']\n",
        "#     cy = M['m01']/M['m00']\n",
        "#     cv2.circle(pp, (int(cx), int(cy)), 1, (255,255,0), -1) \n",
        "#     pc = cv2.drawMarker(pc, (int(cx), int(cy)), (255,255,0), markerType=cv2.MARKER_CROSS, \n",
        "#                    markerSize=5, thickness=1, line_type=cv2.LINE_AA) \n",
        "#     cv2.circle(outputp, (int(cx), int(cy)), 1, (255,255,0), -1) \n",
        "#     outputc = cv2.drawMarker(outputc, (int(cx), int(cy)), (255,255,0), markerType=cv2.MARKER_CROSS, \n",
        "#                    markerSize=5, thickness=1, line_type=cv2.LINE_AA)     \n",
        "#     p.append(points)\n",
        "\n",
        "  \n",
        "#   #plt.imshow(o)\n",
        "#   #plt.show()\n",
        "#   cv2.imwrite(save_name_template[2].format(i), o)\n",
        "\n",
        "#   #plt.imshow(outputp)\n",
        "#   #plt.show()\n",
        "#   cv2.imwrite(save_name_template[5].format(i), outputp)\n",
        "\n",
        "#   #plt.imshow(outputc)\n",
        "#   #plt.show()\n",
        "#   cv2.imwrite(save_name_template[6].format(i), outputc)\n",
        "\n",
        "#   #plt.imshow(pp)\n",
        "#   #plt.show()\n",
        "#   cv2.imwrite(save_name_template[3].format(i), pp)\n",
        "\n",
        "#   #plt.imshow(pc)\n",
        "#   #plt.show()\n",
        "#   cv2.imwrite(save_name_template[4].format(i), pc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}